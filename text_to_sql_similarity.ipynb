{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to SQL Similarity\n",
    "\n",
    "The purpose of this task is to asses your independent work and familiarity with data analysis, Machine Learning and Natural Language Processing techniques. Feel free to use any libraries you want, any models necessary and to define any additional functions you might need. \n",
    "\n",
    "You are given a dataset with questions and their corresponding SQL queries.\n",
    "\n",
    "Tasks:\n",
    "1. Define 2 different similarity metrics between a question and a SQL query (your choice - be creative). The metrics should use different techniques and be based on different models.\n",
    "2. Analyze the similarity metrics you defined above.\n",
    "    \n",
    "    * Define plots to visualize the performance of the similarity metrics (your choice - be creative)\n",
    "    * Define a threshold (and how to choose it) for the similarity metrics to determine if a question is similar to a SQL query.\n",
    "    * Calculate the precision, recall, and F1 score per similarity metric (for the threshold you defined) or other metrics of your choice that will help you compare between the metrics.\n",
    "3. Summarize your findings and conclusions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\text-to-sql-work\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tabulate import tabulate\n",
    "from dotenv import load_dotenv\n",
    "from datasets import Dataset\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, SemanticSimilarity\n",
    "from ragas import evaluate\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 75\n",
      "Number of columns: 3\n",
      "75\n",
      "75\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(df[\"inquiry_id\"].unique().size)\n",
    "print(df[\"question\"].unique().size)\n",
    "print(df[\"sql\"].unique().size)\n",
    "\n",
    "df= df.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inquiry_id    0\n",
      "question      0\n",
      "sql           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI KATANA\\AppData\\Local\\Temp\\ipykernel_30772\\760036421.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else (\"\" if pd.isnull(x) else x))\n"
     ]
    }
   ],
   "source": [
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else (\"\" if pd.isnull(x) else x))\n",
    "print (df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| id |    inquiry_id    |                    question                     |                                                                                                                                          sql                                                                                                                                          |\n",
      "+----+------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| 1  | inquiry_MTzoIbMP | In what countries are most of our jobs offered? | SELECT t.country_name AS Country, COUNT(*) AS Job_Count FROM `draftboard-368620.JEDIFY.job_locations` AS t WHERE t.country_name IS NOT NULL AND t.country_name <> '' AND t.created_at >= '2024-01-01' AND t.created_at < '2024-01-20' GROUP BY t.country_name ORDER BY Job_Count DESC |\n",
      "+----+------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "id_map = {}\n",
    "counter = 1\n",
    "\n",
    "# Step 2: Generate IDs for each row based on inquiry_id\n",
    "def get_or_assign_id(inquiry):\n",
    "    global counter\n",
    "    if inquiry not in id_map:\n",
    "        id_map[inquiry] = counter\n",
    "        counter += 1\n",
    "    return id_map[inquiry]\n",
    "\n",
    "# Add the new 'id' column\n",
    "df[\"id\"] = df[\"inquiry_id\"].apply(get_or_assign_id)\n",
    "\n",
    "column_order = [\"id\", \"inquiry_id\", \"question\", \"sql\"]\n",
    "df = df[column_order]\n",
    "print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_send_LLM=df.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▊       | 2/7 [00:02<00:05,  1.14s/it]No statements were generated from the answer.\n",
      "Evaluating:  71%|███████▏  | 5/7 [00:05<00:02,  1.01s/it]Exception raised in Job[1]: TypeError(ufunc 'invert' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe'')\n",
      "Evaluating: 100%|██████████| 7/7 [00:09<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "df[\"retrieved_contexts\"] = df[\"sql\"].apply(lambda x: [x])  \n",
    "df[\"reference\"] = df[\"question\"]\n",
    "df[\"response\"] = \" \"\n",
    " \n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4-turbo\"))\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    " \n",
    "metrics = [\n",
    "    LLMContextRecall(llm=evaluator_llm),\n",
    "    FactualCorrectness(llm=evaluator_llm),\n",
    "    Faithfulness(llm=evaluator_llm),\n",
    "    SemanticSimilarity(embeddings=evaluator_embeddings),\n",
    "    context_precision ,\n",
    "    answer_relevancy,\n",
    "    context_recall  \n",
    "]\n",
    "\n",
    "\n",
    "results = evaluate(dataset=dataset, metrics=metrics)\n",
    "df_eval = results.to_pandas()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>factual_correctness</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what countries are most of our jobs offered?</td>\n",
       "      <td>[SELECT t.country_name AS Country, COUNT(*) AS...</td>\n",
       "      <td></td>\n",
       "      <td>In what countries are most of our jobs offered?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_input  \\\n",
       "0  In what countries are most of our jobs offered?   \n",
       "\n",
       "                                  retrieved_contexts response  \\\n",
       "0  [SELECT t.country_name AS Country, COUNT(*) AS...            \n",
       "\n",
       "                                         reference  context_recall  \\\n",
       "0  In what countries are most of our jobs offered?             0.0   \n",
       "\n",
       "   factual_correctness  faithfulness  semantic_similarity  context_precision  \\\n",
       "0                  NaN           NaN             0.739802                0.0   \n",
       "\n",
       "   answer_relevancy  \n",
       "0               0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------+----------+\n",
      "| id |    inquiry_id    |                    question                     |                                                                                                                                          sql                                                                                                                                          |                                                                                                                                    retrieved_contexts                                                                                                                                     |                    reference                    | response |\n",
      "+----+------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------+----------+\n",
      "| 1  | inquiry_MTzoIbMP | In what countries are most of our jobs offered? | SELECT t.country_name AS Country, COUNT(*) AS Job_Count FROM `draftboard-368620.JEDIFY.job_locations` AS t WHERE t.country_name IS NOT NULL AND t.country_name <> '' AND t.created_at >= '2024-01-01' AND t.created_at < '2024-01-20' GROUP BY t.country_name ORDER BY Job_Count DESC | [\"SELECT t.country_name AS Country, COUNT(*) AS Job_Count FROM `draftboard-368620.JEDIFY.job_locations` AS t WHERE t.country_name IS NOT NULL AND t.country_name <> '' AND t.created_at >= '2024-01-01' AND t.created_at < '2024-01-20' GROUP BY t.country_name ORDER BY Job_Count DESC\"] | In what countries are most of our jobs offered? |          |\n",
      "+----+------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| id |    inquiry_id    |                    question                     |                                                                                                                                          sql                                                                                                                                          |                                                                                                                                    retrieved_contexts                                                                                                                                     |                    reference                    | response |                                                                                   predicted_question                                                                                   | similarity_score | sql_matching_scores |\n",
      "+----+------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 1  | inquiry_MTzoIbMP | In what countries are most of our jobs offered? | SELECT t.country_name AS Country, COUNT(*) AS Job_Count FROM `draftboard-368620.JEDIFY.job_locations` AS t WHERE t.country_name IS NOT NULL AND t.country_name <> '' AND t.created_at >= '2024-01-01' AND t.created_at < '2024-01-20' GROUP BY t.country_name ORDER BY Job_Count DESC | [\"SELECT t.country_name AS Country, COUNT(*) AS Job_Count FROM `draftboard-368620.JEDIFY.job_locations` AS t WHERE t.country_name IS NOT NULL AND t.country_name <> '' AND t.created_at >= '2024-01-01' AND t.created_at < '2024-01-20' GROUP BY t.country_name ORDER BY Job_Count DESC\"] | In what countries are most of our jobs offered? |          | What are the counts of jobs by country, excluding null or empty country names, created between January 1, 2024 and January 20, 2024, ordered by the count of jobs in descending order? |       0.35       |        0.35         |\n",
      "+----+------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "from openai import OpenAI\n",
    "\n",
    "openai.api_key =  OPENAI_API_KEY\n",
    "client = OpenAI()\n",
    " \n",
    "\n",
    "# Function to predict the question based on SQL query\n",
    "def get_predicted_question(sql_query):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant who is really good at generating questions for SQL queries.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Generate the question that the following SQL query is answering:\\n\\n{sql_query}\"}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def get_similarity_score(original_question, predicted_question):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant who is really good at sentence similarity matching.And you give the output always as a float number only. you never provide a String value or the descrition about your response\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Rate the similarity between these two questions on a scale from 0 to 1 (1 being identical). Make sure your only allowed response is only a float value with maximum 2 demial points. finla response only need to be that:\\n\\n1. {original_question}\\n2. {predicted_question}\"}\n",
    "        ]\n",
    "    )\n",
    "    return  completion.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def get_direct_query_match_score(original_question, sql_query):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant who is really good at   matching the relavancy of the sql query and the it's original question . you always give response as a interger only.every time your answer is a number . there is no explnation   \"},\n",
    "            {\"role\": \"user\", \"content\": f\"Rate the realavancy between these   questions  and the sql statement  on a scale from 0 to 1 (1 being identical). Make sure your only allowed response is only a float value with maximum 2 demial points. finla response only need to be that:\\n\\n1. {original_question}\\n2. {predicted_question}\"}\n",
    "        ]\n",
    "    )\n",
    "    return  completion.choices[0].message.content.strip()\n",
    "\n",
    "predicted_questions = []\n",
    "similarity_scores = []\n",
    "sql_matching_scores = []\n",
    "\n",
    " \n",
    "for index, row in df.iterrows():\n",
    "    sql_query = row[\"sql\"]\n",
    "    original_question = row[\"question\"]\n",
    "    \n",
    "    # Get predicted question\n",
    "    predicted_question = get_predicted_question(sql_query)\n",
    "    predicted_questions.append(predicted_question)\n",
    "    sql_matching_scores.append(get_direct_query_match_score(original_question ,original_question))\n",
    "    \n",
    "    # Calculate similarity score\n",
    "    similarity_score = get_similarity_score(original_question, predicted_question)\n",
    "    similarity_scores.append(similarity_score)\n",
    "\n",
    "# Add results to DataFrame\n",
    "df[\"predicted_question\"] = predicted_questions\n",
    "df[\"similarity_score\"] = similarity_scores\n",
    "df[\"sql_matching_scores\"] = similarity_scores\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Selection Metric 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Selection Metric 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
